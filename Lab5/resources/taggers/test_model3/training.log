2025-10-23 07:05:33,058 ----------------------------------------------------------------------------------------------------
2025-10-23 07:05:33,060 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)
  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=19, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2025-10-23 07:05:33,061 ----------------------------------------------------------------------------------------------------
2025-10-23 07:05:33,063 Corpus: 14987 train + 3466 dev + 3684 test sentences
2025-10-23 07:05:33,064 ----------------------------------------------------------------------------------------------------
2025-10-23 07:05:33,065 Train:  14987 sentences
2025-10-23 07:05:33,068         (train_with_dev=False, train_with_test=False)
2025-10-23 07:05:33,069 ----------------------------------------------------------------------------------------------------
2025-10-23 07:05:33,071 Training Params:
2025-10-23 07:05:33,072  - learning_rate: "0.1" 
2025-10-23 07:05:33,074  - mini_batch_size: "32"
2025-10-23 07:05:33,074  - max_epochs: "10"
2025-10-23 07:05:33,076  - shuffle: "True"
2025-10-23 07:05:33,078 ----------------------------------------------------------------------------------------------------
2025-10-23 07:05:33,079 Plugins:
2025-10-23 07:05:33,080  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'
2025-10-23 07:05:33,083 ----------------------------------------------------------------------------------------------------
2025-10-23 07:05:33,085 Final evaluation on model from best epoch (best-model.pt)
2025-10-23 07:05:33,087  - metric: "('micro avg', 'f1-score')"
2025-10-23 07:05:33,088 ----------------------------------------------------------------------------------------------------
2025-10-23 07:05:33,090 Computation:
2025-10-23 07:05:33,093  - compute on device: cuda:0
2025-10-23 07:05:33,095  - embedding storage: cpu
2025-10-23 07:05:33,096 ----------------------------------------------------------------------------------------------------
2025-10-23 07:05:33,097 Model training base path: "resources/taggers/test_model3"
2025-10-23 07:05:33,098 ----------------------------------------------------------------------------------------------------
2025-10-23 07:05:33,100 ----------------------------------------------------------------------------------------------------
2025-10-23 07:05:49,392 epoch 1 - iter 46/469 - loss 0.65922748 - time (sec): 16.29 - samples/sec: 1230.49 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:06:08,634 epoch 1 - iter 92/469 - loss 0.47986825 - time (sec): 35.53 - samples/sec: 1140.36 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:06:26,056 epoch 1 - iter 138/469 - loss 0.39030683 - time (sec): 52.95 - samples/sec: 1144.51 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:06:43,451 epoch 1 - iter 184/469 - loss 0.34050304 - time (sec): 70.35 - samples/sec: 1138.79 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:07:01,286 epoch 1 - iter 230/469 - loss 0.30753062 - time (sec): 88.18 - samples/sec: 1132.13 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:07:19,695 epoch 1 - iter 276/469 - loss 0.28147295 - time (sec): 106.59 - samples/sec: 1127.82 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:07:38,185 epoch 1 - iter 322/469 - loss 0.26071001 - time (sec): 125.08 - samples/sec: 1124.95 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:07:56,877 epoch 1 - iter 368/469 - loss 0.24460923 - time (sec): 143.77 - samples/sec: 1116.03 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:08:15,111 epoch 1 - iter 414/469 - loss 0.23180572 - time (sec): 162.01 - samples/sec: 1111.16 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:08:34,299 epoch 1 - iter 460/469 - loss 0.21965514 - time (sec): 181.20 - samples/sec: 1108.06 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:08:37,695 ----------------------------------------------------------------------------------------------------
2025-10-23 07:08:37,697 EPOCH 1 done: loss 0.2175 - lr: 0.100000
2025-10-23 07:08:37,698 Saving model at current epoch since 'save_model_each_k_epochs=1' was set
2025-10-23 07:09:18,042 DEV : loss 0.06436935812234879 - f1-score (micro avg)  0.9035
2025-10-23 07:09:53,811 TEST : loss 0.08344743400812149 - f1-score (micro avg)  0.8684
2025-10-23 07:09:53,986  - 0 epochs without improvement
2025-10-23 07:09:53,996 saving best model
2025-10-23 07:09:59,012 ----------------------------------------------------------------------------------------------------
2025-10-23 07:10:04,245 epoch 2 - iter 46/469 - loss 0.10601288 - time (sec): 5.23 - samples/sec: 3995.76 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:10:10,771 epoch 2 - iter 92/469 - loss 0.10543593 - time (sec): 11.76 - samples/sec: 3448.67 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:10:15,961 epoch 2 - iter 138/469 - loss 0.10265364 - time (sec): 16.95 - samples/sec: 3556.34 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:10:21,771 epoch 2 - iter 184/469 - loss 0.09843453 - time (sec): 22.76 - samples/sec: 3553.19 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:10:26,521 epoch 2 - iter 230/469 - loss 0.09737160 - time (sec): 27.51 - samples/sec: 3691.43 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:10:31,661 epoch 2 - iter 276/469 - loss 0.09632324 - time (sec): 32.65 - samples/sec: 3729.66 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:10:36,936 epoch 2 - iter 322/469 - loss 0.09650885 - time (sec): 37.92 - samples/sec: 3730.79 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:10:41,735 epoch 2 - iter 368/469 - loss 0.09531949 - time (sec): 42.72 - samples/sec: 3791.25 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:10:47,401 epoch 2 - iter 414/469 - loss 0.09441766 - time (sec): 48.39 - samples/sec: 3755.64 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:10:52,191 epoch 2 - iter 460/469 - loss 0.09386303 - time (sec): 53.18 - samples/sec: 3777.72 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:10:53,146 ----------------------------------------------------------------------------------------------------
2025-10-23 07:10:53,147 EPOCH 2 done: loss 0.0934 - lr: 0.100000
2025-10-23 07:10:53,148 Saving model at current epoch since 'save_model_each_k_epochs=1' was set
2025-10-23 07:11:14,924 DEV : loss 0.0496218167245388 - f1-score (micro avg)  0.9224
2025-10-23 07:11:29,527 TEST : loss 0.06871791929006577 - f1-score (micro avg)  0.8969
2025-10-23 07:11:29,696  - 0 epochs without improvement
2025-10-23 07:11:29,704 saving best model
2025-10-23 07:11:37,007 ----------------------------------------------------------------------------------------------------
2025-10-23 07:11:43,028 epoch 3 - iter 46/469 - loss 0.07493957 - time (sec): 6.02 - samples/sec: 3454.80 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:11:47,860 epoch 3 - iter 92/469 - loss 0.07866808 - time (sec): 10.85 - samples/sec: 3694.73 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:11:56,070 epoch 3 - iter 138/469 - loss 0.07712368 - time (sec): 19.06 - samples/sec: 3160.07 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:12:01,407 epoch 3 - iter 184/469 - loss 0.07757277 - time (sec): 24.40 - samples/sec: 3298.30 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:12:06,612 epoch 3 - iter 230/469 - loss 0.07703605 - time (sec): 29.60 - samples/sec: 3397.05 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:12:12,109 epoch 3 - iter 276/469 - loss 0.07612743 - time (sec): 35.10 - samples/sec: 3431.60 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:12:16,827 epoch 3 - iter 322/469 - loss 0.07584295 - time (sec): 39.82 - samples/sec: 3518.75 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:12:22,419 epoch 3 - iter 368/469 - loss 0.07509418 - time (sec): 45.41 - samples/sec: 3521.66 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:12:27,241 epoch 3 - iter 414/469 - loss 0.07449855 - time (sec): 50.23 - samples/sec: 3597.73 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:12:32,327 epoch 3 - iter 460/469 - loss 0.07390665 - time (sec): 55.32 - samples/sec: 3629.55 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:12:33,582 ----------------------------------------------------------------------------------------------------
2025-10-23 07:12:33,584 EPOCH 3 done: loss 0.0737 - lr: 0.100000
2025-10-23 07:12:33,585 Saving model at current epoch since 'save_model_each_k_epochs=1' was set
2025-10-23 07:12:52,534 DEV : loss 0.042316000908613205 - f1-score (micro avg)  0.9209
2025-10-23 07:13:07,199 TEST : loss 0.07065945118665695 - f1-score (micro avg)  0.8897
2025-10-23 07:13:07,382  - 1 epochs without improvement
2025-10-23 07:13:07,389 ----------------------------------------------------------------------------------------------------
2025-10-23 07:13:12,756 epoch 4 - iter 46/469 - loss 0.07151104 - time (sec): 5.37 - samples/sec: 3777.42 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:13:18,023 epoch 4 - iter 92/469 - loss 0.06499676 - time (sec): 10.63 - samples/sec: 3812.21 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:13:22,769 epoch 4 - iter 138/469 - loss 0.06377862 - time (sec): 15.38 - samples/sec: 3931.65 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:13:28,366 epoch 4 - iter 184/469 - loss 0.06447903 - time (sec): 20.97 - samples/sec: 3861.66 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:13:32,893 epoch 4 - iter 230/469 - loss 0.06430703 - time (sec): 25.50 - samples/sec: 3925.35 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:13:37,818 epoch 4 - iter 276/469 - loss 0.06314246 - time (sec): 30.43 - samples/sec: 3946.71 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:13:43,283 epoch 4 - iter 322/469 - loss 0.06283566 - time (sec): 35.89 - samples/sec: 3903.10 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:13:47,977 epoch 4 - iter 368/469 - loss 0.06273898 - time (sec): 40.59 - samples/sec: 3941.92 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:13:53,790 epoch 4 - iter 414/469 - loss 0.06240305 - time (sec): 46.40 - samples/sec: 3888.62 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:13:58,629 epoch 4 - iter 460/469 - loss 0.06201107 - time (sec): 51.24 - samples/sec: 3913.92 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:13:59,586 ----------------------------------------------------------------------------------------------------
2025-10-23 07:13:59,587 EPOCH 4 done: loss 0.0619 - lr: 0.100000
2025-10-23 07:13:59,588 Saving model at current epoch since 'save_model_each_k_epochs=1' was set
2025-10-23 07:14:24,138 DEV : loss 0.03597095236182213 - f1-score (micro avg)  0.9362
2025-10-23 07:14:38,997 TEST : loss 0.06460199505090714 - f1-score (micro avg)  0.9072
2025-10-23 07:14:39,167  - 0 epochs without improvement
2025-10-23 07:14:39,175 saving best model
2025-10-23 07:14:59,765 ----------------------------------------------------------------------------------------------------
2025-10-23 07:15:04,582 epoch 5 - iter 46/469 - loss 0.05490601 - time (sec): 4.81 - samples/sec: 4165.97 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:15:11,020 epoch 5 - iter 92/469 - loss 0.05391670 - time (sec): 11.25 - samples/sec: 3580.91 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:15:18,083 epoch 5 - iter 138/469 - loss 0.05551634 - time (sec): 18.31 - samples/sec: 3309.45 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:15:23,103 epoch 5 - iter 184/469 - loss 0.05338851 - time (sec): 23.33 - samples/sec: 3455.78 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:15:28,830 epoch 5 - iter 230/469 - loss 0.05356722 - time (sec): 29.06 - samples/sec: 3481.45 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:15:33,547 epoch 5 - iter 276/469 - loss 0.05405528 - time (sec): 33.78 - samples/sec: 3579.52 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:15:39,116 epoch 5 - iter 322/469 - loss 0.05432694 - time (sec): 39.35 - samples/sec: 3579.18 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:15:44,094 epoch 5 - iter 368/469 - loss 0.05510320 - time (sec): 44.32 - samples/sec: 3634.83 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:15:48,917 epoch 5 - iter 414/469 - loss 0.05501361 - time (sec): 49.15 - samples/sec: 3681.77 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:15:54,612 epoch 5 - iter 460/469 - loss 0.05458436 - time (sec): 54.84 - samples/sec: 3665.72 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:15:55,490 ----------------------------------------------------------------------------------------------------
2025-10-23 07:15:55,491 EPOCH 5 done: loss 0.0546 - lr: 0.100000
2025-10-23 07:15:55,492 Saving model at current epoch since 'save_model_each_k_epochs=1' was set
2025-10-23 07:16:24,159 DEV : loss 0.035159531980752945 - f1-score (micro avg)  0.9377
2025-10-23 07:16:41,865 TEST : loss 0.06548133492469788 - f1-score (micro avg)  0.9102
2025-10-23 07:16:42,158  - 0 epochs without improvement
2025-10-23 07:16:42,166 saving best model
2025-10-23 07:16:58,249 ----------------------------------------------------------------------------------------------------
2025-10-23 07:17:03,200 epoch 6 - iter 46/469 - loss 0.05127471 - time (sec): 4.95 - samples/sec: 4135.77 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:17:08,519 epoch 6 - iter 92/469 - loss 0.04829387 - time (sec): 10.27 - samples/sec: 3942.52 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:17:16,130 epoch 6 - iter 138/469 - loss 0.04865535 - time (sec): 17.88 - samples/sec: 3386.08 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:17:21,594 epoch 6 - iter 184/469 - loss 0.04846912 - time (sec): 23.34 - samples/sec: 3448.91 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:17:27,373 epoch 6 - iter 230/469 - loss 0.04796907 - time (sec): 29.12 - samples/sec: 3466.00 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:17:32,105 epoch 6 - iter 276/469 - loss 0.04727644 - time (sec): 33.85 - samples/sec: 3566.12 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:17:37,692 epoch 6 - iter 322/469 - loss 0.04777116 - time (sec): 39.44 - samples/sec: 3552.65 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:17:42,361 epoch 6 - iter 368/469 - loss 0.04820940 - time (sec): 44.11 - samples/sec: 3626.68 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:17:47,296 epoch 6 - iter 414/469 - loss 0.04821594 - time (sec): 49.04 - samples/sec: 3695.36 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:17:53,188 epoch 6 - iter 460/469 - loss 0.04820483 - time (sec): 54.94 - samples/sec: 3656.98 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:17:54,084 ----------------------------------------------------------------------------------------------------
2025-10-23 07:17:54,085 EPOCH 6 done: loss 0.0482 - lr: 0.100000
2025-10-23 07:17:54,087 Saving model at current epoch since 'save_model_each_k_epochs=1' was set
2025-10-23 07:18:35,411 DEV : loss 0.0314440093934536 - f1-score (micro avg)  0.9464
2025-10-23 07:18:50,352 TEST : loss 0.06495039165019989 - f1-score (micro avg)  0.9107
2025-10-23 07:18:50,520  - 0 epochs without improvement
2025-10-23 07:18:50,528 saving best model
2025-10-23 07:19:05,960 ----------------------------------------------------------------------------------------------------
2025-10-23 07:19:11,309 epoch 7 - iter 46/469 - loss 0.04670993 - time (sec): 5.34 - samples/sec: 3823.27 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:19:16,383 epoch 7 - iter 92/469 - loss 0.04486602 - time (sec): 10.42 - samples/sec: 3888.33 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:19:25,067 epoch 7 - iter 138/469 - loss 0.04399578 - time (sec): 19.10 - samples/sec: 3136.34 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:19:30,067 epoch 7 - iter 184/469 - loss 0.04431703 - time (sec): 24.10 - samples/sec: 3331.20 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:19:36,202 epoch 7 - iter 230/469 - loss 0.04424523 - time (sec): 30.24 - samples/sec: 3320.45 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:19:41,163 epoch 7 - iter 276/469 - loss 0.04472902 - time (sec): 35.20 - samples/sec: 3436.85 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:19:46,398 epoch 7 - iter 322/469 - loss 0.04469568 - time (sec): 40.43 - samples/sec: 3485.52 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:19:52,333 epoch 7 - iter 368/469 - loss 0.04430708 - time (sec): 46.37 - samples/sec: 3470.40 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:19:57,857 epoch 7 - iter 414/469 - loss 0.04412725 - time (sec): 51.89 - samples/sec: 3489.06 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:20:03,745 epoch 7 - iter 460/469 - loss 0.04415163 - time (sec): 57.78 - samples/sec: 3480.19 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:20:04,621 ----------------------------------------------------------------------------------------------------
2025-10-23 07:20:04,622 EPOCH 7 done: loss 0.0444 - lr: 0.100000
2025-10-23 07:20:04,623 Saving model at current epoch since 'save_model_each_k_epochs=1' was set
2025-10-23 07:20:37,852 DEV : loss 0.030480969697237015 - f1-score (micro avg)  0.9438
2025-10-23 07:20:55,624 TEST : loss 0.05669871345162392 - f1-score (micro avg)  0.92
2025-10-23 07:20:55,800  - 1 epochs without improvement
2025-10-23 07:20:55,807 ----------------------------------------------------------------------------------------------------
2025-10-23 07:21:00,732 epoch 8 - iter 46/469 - loss 0.03726526 - time (sec): 4.92 - samples/sec: 4112.89 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:21:05,937 epoch 8 - iter 92/469 - loss 0.03880044 - time (sec): 10.13 - samples/sec: 3955.50 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:21:10,981 epoch 8 - iter 138/469 - loss 0.03956667 - time (sec): 15.17 - samples/sec: 3974.41 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:21:15,586 epoch 8 - iter 184/469 - loss 0.04033563 - time (sec): 19.78 - samples/sec: 4034.00 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:21:21,121 epoch 8 - iter 230/469 - loss 0.04008297 - time (sec): 25.31 - samples/sec: 3956.52 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:21:25,717 epoch 8 - iter 276/469 - loss 0.04073503 - time (sec): 29.91 - samples/sec: 4000.51 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:21:30,785 epoch 8 - iter 322/469 - loss 0.04124462 - time (sec): 34.98 - samples/sec: 4010.82 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:21:36,005 epoch 8 - iter 368/469 - loss 0.04132103 - time (sec): 40.20 - samples/sec: 3980.63 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:21:40,704 epoch 8 - iter 414/469 - loss 0.04173612 - time (sec): 44.90 - samples/sec: 4019.18 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:21:46,365 epoch 8 - iter 460/469 - loss 0.04169196 - time (sec): 50.56 - samples/sec: 3973.67 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:21:47,326 ----------------------------------------------------------------------------------------------------
2025-10-23 07:21:47,328 EPOCH 8 done: loss 0.0416 - lr: 0.100000
2025-10-23 07:21:47,329 Saving model at current epoch since 'save_model_each_k_epochs=1' was set
2025-10-23 07:22:19,894 DEV : loss 0.0327884778380394 - f1-score (micro avg)  0.9402
2025-10-23 07:22:34,661 TEST : loss 0.0608903244137764 - f1-score (micro avg)  0.9143
2025-10-23 07:22:34,849  - 2 epochs without improvement
2025-10-23 07:22:34,856 ----------------------------------------------------------------------------------------------------
2025-10-23 07:22:40,942 epoch 9 - iter 46/469 - loss 0.03650362 - time (sec): 6.08 - samples/sec: 3296.88 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:22:45,819 epoch 9 - iter 92/469 - loss 0.03702396 - time (sec): 10.96 - samples/sec: 3668.27 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:22:51,254 epoch 9 - iter 138/469 - loss 0.03771553 - time (sec): 16.40 - samples/sec: 3673.95 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:22:56,490 epoch 9 - iter 184/469 - loss 0.03881159 - time (sec): 21.63 - samples/sec: 3722.48 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:23:01,326 epoch 9 - iter 230/469 - loss 0.03906141 - time (sec): 26.47 - samples/sec: 3791.98 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:23:06,913 epoch 9 - iter 276/469 - loss 0.03860595 - time (sec): 32.06 - samples/sec: 3766.44 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:23:11,631 epoch 9 - iter 322/469 - loss 0.03875522 - time (sec): 36.77 - samples/sec: 3826.29 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:23:16,614 epoch 9 - iter 368/469 - loss 0.03886292 - time (sec): 41.76 - samples/sec: 3845.62 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:23:21,991 epoch 9 - iter 414/469 - loss 0.03925226 - time (sec): 47.13 - samples/sec: 3832.98 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:23:26,746 epoch 9 - iter 460/469 - loss 0.03991387 - time (sec): 51.89 - samples/sec: 3873.81 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:23:27,669 ----------------------------------------------------------------------------------------------------
2025-10-23 07:23:27,670 EPOCH 9 done: loss 0.0399 - lr: 0.100000
2025-10-23 07:23:27,671 Saving model at current epoch since 'save_model_each_k_epochs=1' was set
2025-10-23 07:24:03,595 DEV : loss 0.031058382242918015 - f1-score (micro avg)  0.9467
2025-10-23 07:24:18,570 TEST : loss 0.05998992174863815 - f1-score (micro avg)  0.9179
2025-10-23 07:24:18,756  - 0 epochs without improvement
2025-10-23 07:24:18,762 saving best model
2025-10-23 07:24:37,253 ----------------------------------------------------------------------------------------------------
2025-10-23 07:24:42,104 epoch 10 - iter 46/469 - loss 0.03328890 - time (sec): 4.85 - samples/sec: 4158.27 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:24:48,658 epoch 10 - iter 92/469 - loss 0.03670395 - time (sec): 11.40 - samples/sec: 3522.11 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:24:55,806 epoch 10 - iter 138/469 - loss 0.03675858 - time (sec): 18.55 - samples/sec: 3261.53 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:25:02,039 epoch 10 - iter 184/469 - loss 0.03621460 - time (sec): 24.78 - samples/sec: 3241.59 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:25:07,417 epoch 10 - iter 230/469 - loss 0.03703499 - time (sec): 30.16 - samples/sec: 3314.95 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:25:12,213 epoch 10 - iter 276/469 - loss 0.03747101 - time (sec): 34.96 - samples/sec: 3451.50 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:25:17,728 epoch 10 - iter 322/469 - loss 0.03728571 - time (sec): 40.47 - samples/sec: 3487.54 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:25:22,351 epoch 10 - iter 368/469 - loss 0.03753813 - time (sec): 45.10 - samples/sec: 3584.04 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:25:27,169 epoch 10 - iter 414/469 - loss 0.03806003 - time (sec): 49.91 - samples/sec: 3633.66 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:25:32,725 epoch 10 - iter 460/469 - loss 0.03854365 - time (sec): 55.47 - samples/sec: 3623.26 - lr: 0.100000 - momentum: 0.000000
2025-10-23 07:25:33,576 ----------------------------------------------------------------------------------------------------
2025-10-23 07:25:33,577 EPOCH 10 done: loss 0.0386 - lr: 0.100000
2025-10-23 07:25:33,578 Saving model at current epoch since 'save_model_each_k_epochs=1' was set
2025-10-23 07:26:13,097 DEV : loss 0.028916511684656143 - f1-score (micro avg)  0.9495
2025-10-23 07:26:27,876 TEST : loss 0.06026919558644295 - f1-score (micro avg)  0.9185
2025-10-23 07:26:28,044  - 0 epochs without improvement
2025-10-23 07:26:28,052 saving best model
2025-10-23 07:27:08,684 ----------------------------------------------------------------------------------------------------
2025-10-23 07:27:08,710 Loading model from best epoch ...
2025-10-23 07:27:11,104 SequenceTagger predicts: Dictionary with 19 tags: O, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-ORG, B-ORG, E-ORG, I-ORG, S-MISC, B-MISC, E-MISC, I-MISC, <START>, <STOP>
2025-10-23 07:27:31,316 
Results:
- F-score (micro) 0.9185
- F-score (macro) 0.9049
- Accuracy 0.8796

By class:
              precision    recall  f1-score   support

         LOC     0.9307    0.9335    0.9321      1668
         ORG     0.8935    0.9037    0.8985      1661
         PER     0.9638    0.9703    0.9670      1617
        MISC     0.8151    0.8291    0.8220       702

   micro avg     0.9147    0.9223    0.9185      5648
   macro avg     0.9008    0.9091    0.9049      5648
weighted avg     0.9148    0.9223    0.9185      5648

2025-10-23 07:27:31,317 ----------------------------------------------------------------------------------------------------

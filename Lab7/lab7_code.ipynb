{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dafc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceaa104",
   "metadata": {},
   "source": [
    "# Question (a)\n",
    "Wordnet exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd7ccc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 synsets for 'sink':\n",
      "Synset('sink.n.01')\n",
      "Synset('sink.n.02')\n",
      "Synset('sinkhole.n.01')\n",
      "Synset('cesspool.n.01')\n",
      "Synset('sink.v.01')\n",
      "Synset('sink.v.02')\n",
      "Synset('sink.v.03')\n",
      "Synset('sink.v.04')\n",
      "Synset('sink.v.05')\n",
      "Synset('dip.v.08')\n",
      "Synset('slump.v.03')\n",
      "Synset('slump.v.02')\n",
      "Synset('bury.v.05')\n"
     ]
    }
   ],
   "source": [
    "# Synsets for 'sink'\n",
    "sink_synsets = wn.synsets(\"sink\")\n",
    "print(f\"There are {len(sink_synsets)} synsets for 'sink':\")\n",
    "\n",
    "for synset in sink_synsets:\n",
    "    print(synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95dd1b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('plumbing_fixture.n.01')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Direct hypernym of most common noun sense of 'sink'\n",
    "synset_noun_sink = wn.synset(\"sink.n.01\")\n",
    "synset_noun_sink.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12661e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('drain_the_cup.v.01'),\n",
       " Synset('guggle.v.03'),\n",
       " Synset('suck.v.01'),\n",
       " Synset('toss_off.v.02'),\n",
       " Synset('lap.v.04'),\n",
       " Synset('gulp.v.01'),\n",
       " Synset('sip.v.01'),\n",
       " Synset('swill.v.02'),\n",
       " Synset('guzzle.v.01')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Direct troponym of most common verb sense 'drink'\n",
    "synset_verb_drink = wn.synset(\"drink.v.01\")\n",
    "synset_verb_drink.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07a9b0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('animal.n.01')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Closest ancestor for most common noun sense 'dog' and 'insect'\n",
    "synset_noun_dog = wn.synset(\"dog.n.01\")\n",
    "synset_noun_insect = wn.synset(\"insect.n.01\")\n",
    "synset_noun_dog.lowest_common_hypernyms(synset_noun_insect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6859725b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('gagarin.n.01'),\n",
       " Synset('armstrong.n.01'),\n",
       " Synset('glenn.n.01'),\n",
       " Synset('shepard.n.02'),\n",
       " Synset('tereshkova.n.01')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Astronauts that are instances of most common noun sense 'astronaut'\n",
    "synset_noun_astronaut = wn.synset(\"astronaut.n.01\")\n",
    "synset_noun_astronaut.instance_hyponyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6db690",
   "metadata": {},
   "source": [
    "# Question (b)\n",
    "Implement Hearst Pattern matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1338e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_noun_phrases(sentence: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Identify noun phrases in a sentence using nltk pos tagging.\n",
    "    \"\"\"\n",
    "    print(f\"Extracting NPs..\")\n",
    "    # Tokenize sentence\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "    # Use NP specific grammar to identify NPs\n",
    "    NP_grammer = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "    chunk_parser = nltk.RegexpParser(NP_grammer)\n",
    "    results = chunk_parser.parse(pos_tags)\n",
    "\n",
    "    # Iterate through each subtree\n",
    "    NPs = []\n",
    "    for tree in results.subtrees():\n",
    "        if tree.label() == \"NP\":\n",
    "            # Obtain all words under the NP branch\n",
    "            words = [w for w, _ in tree.leaves()]\n",
    "            NPs.append(\" \".join(words))\n",
    "\n",
    "    return NPs\n",
    "\n",
    "\n",
    "def extract_hypernyms(\n",
    "    sentence: str, pattern_type: int\n",
    ") -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Extracts candidate hypernyms from a sentence using Hearst Pattern regex matching.\n",
    "    \"\"\"\n",
    "    print(f\"Pattern type {pattern_type} chosen...\")\n",
    "    # Regex for word boundaries (use NP as placeholder)\n",
    "    NP = \"\\w+(-?\\w+)(\\s\\w+(-?\\w+))?\"\n",
    "\n",
    "    # Use regex to extract NPs\n",
    "    print(f\"Extracting hypernyms using regex...\")\n",
    "    if pattern_type == 1:\n",
    "        # Hearst Pattern 1: NP {,} especially {NP,}* {or|and} NP\n",
    "        hp1 = rf\"{NP},? especially ({NP},? )*(or|and)? {NP}\"\n",
    "        delimiter1 = r\",? especially \"\n",
    "\n",
    "        match = re.search(hp1, sentence)\n",
    "        if match:\n",
    "            candidate_words = re.split(\n",
    "                delimiter1, match.group()\n",
    "            )\n",
    "\n",
    "            # Hypernym is before delimiter\n",
    "            before_delim = candidate_words[0]\n",
    "            hypernym = identify_noun_phrases(before_delim)\n",
    "            if len(hypernym) == 0:\n",
    "                # Use entire phrase if no NPs found\n",
    "                hypernym = before_delim\n",
    "\n",
    "            # Hyponyms is after delimiter, either within commas or separated by or/and\n",
    "            after_delim1 = re.split(\n",
    "                r\", \", candidate_words[1]\n",
    "            )[0:-1]\n",
    "            after_delim2 = re.split(\n",
    "                r\",? or|and \", candidate_words[1]\n",
    "            )[-1]\n",
    "            hyponyms = after_delim1 + [after_delim2]\n",
    "\n",
    "        else:\n",
    "            print(\"No match found.\")\n",
    "            return None, None\n",
    "\n",
    "    else:\n",
    "        # Hearst Pattern 2: NP {, NP}*{,} and other NP\n",
    "        hp2 = rf\"{NP}(,? {NP})*,? and other {NP}\"\n",
    "        delimiter2 = r\",? and other \"\n",
    "\n",
    "        match = re.search(hp2, sentence)\n",
    "        if match:\n",
    "            candidate_words = re.split(\n",
    "                delimiter2, match.group()\n",
    "            )\n",
    "\n",
    "            # Hypernym is after delimiter\n",
    "            hypernym = identify_noun_phrases(\n",
    "                candidate_words[-1]\n",
    "            )\n",
    "            if len(hypernym) == 0:\n",
    "                # Use entire phrase if no NPs found\n",
    "                hypernym = candidate_words[-1]\n",
    "\n",
    "            # Hyponyms is before delimiter, within commas\n",
    "            hyponyms = re.split(r\", \", candidate_words[0])\n",
    "\n",
    "        else:\n",
    "            print(\"No match found.\")\n",
    "            return None, None\n",
    "\n",
    "    return hypernym, hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick sentences from test set to test hypernym indentification\n",
    "test = \"Charles L. Harris, as leader of the Baltimore Colored City Band, took his group to black neighborhoods across Baltimore, playing marches, waltzes and other music, then switch to jazz-like music with an upbeat tempo, meant for dancing.\"\n",
    "hypernym, hyponym = extract_hypernyms(test, pattern_type=2)\n",
    "\n",
    "print(f\"Extracted hypernym: {hypernym}\")\n",
    "print(f\"Extracted hyponyms: {hyponym}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad84258",
   "metadata": {},
   "source": [
    "# Question (c)\n",
    "Implement extension: extracting meronyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e7a92abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_noun_phrases(sentence: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Identify noun phrases in a sentence using nltk pos tagging.\n",
    "    \"\"\"\n",
    "    print(f\"Extracting NPs..\")\n",
    "    # Tokenize sentence\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "    # Use NP specific grammar to identify NPs\n",
    "    NP_grammer = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "    chunk_parser = nltk.RegexpParser(NP_grammer)\n",
    "    results = chunk_parser.parse(pos_tags)\n",
    "\n",
    "    # Iterate through each subtree\n",
    "    NPs = []\n",
    "    for tree in results.subtrees():\n",
    "        if tree.label() == \"NP\":\n",
    "            # Obtain all words under the NP branch\n",
    "            words = [w for w, _ in tree.leaves()]\n",
    "            NPs.append(\" \".join(words))\n",
    "\n",
    "    return NPs\n",
    "\n",
    "\n",
    "def extract_meronyms(sentence: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Extracts candidate meronyms from a sentence using regex matching.\n",
    "    \"\"\"\n",
    "    # Regex for word boundaries (use NP as placeholder)\n",
    "    NP = \"\\w+(-?\\w+)(\\s\\w+(-?\\w+))?\"\n",
    "\n",
    "    print(f\"Extracting meronyms using regex...\")\n",
    "    # Meronym pattern: NP {is|as} part of NP\n",
    "    pattern = rf\"{NP},?( is|as )? part of {NP}\"\n",
    "    match = re.search(pattern, sentence)\n",
    "\n",
    "    # Use delimiter to split meronym and holonym\n",
    "    delim = \"part of\"\n",
    "    if match:\n",
    "        candidate_words = re.split(delim, match.group())\n",
    "        print(candidate_words)\n",
    "        # Meronym is before delimiter\n",
    "        meronym = identify_noun_phrases(candidate_words[0])\n",
    "        if len(meronym) == 0:\n",
    "            # Use entire phrase if no NPs found\n",
    "            meronym = candidate_words[0]\n",
    "\n",
    "        # Holonym is after delimiter\n",
    "        holonym = identify_noun_phrases(candidate_words[1])\n",
    "        if len(holonym) == 0:\n",
    "            # Use entire phrase if no NPs found\n",
    "            holonym = candidate_words[1]\n",
    "\n",
    "    else:\n",
    "        print(\"No match found.\")\n",
    "        return None, None\n",
    "\n",
    "    return meronym, holonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f857a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting meronyms using regex...\n",
      "No match found.\n",
      "Extracted meronym: None\n",
      "Extracted holonym: None\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Additional attention has been directed to wastewater treatment, urban stormwater runoff, and wetland protection.\"\n",
    "meronym, holonym = extract_meronyms(sentence)\n",
    "\n",
    "print(f\"Extracted meronym: {meronym}\")\n",
    "print(f\"Extracted holonym: {holonym}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
